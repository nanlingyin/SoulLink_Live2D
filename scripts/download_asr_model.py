#!/usr/bin/env python3
"""
Whisper ASR æ¨¡å‹ä¸‹è½½è„šæœ¬
ä¸‹è½½ OpenAI Whisper æ¨¡å‹ç”¨äºæœ¬åœ°è¯­éŸ³è¯†åˆ«
"""

import argparse
import os
import sys
from pathlib import Path

# æ¨¡å‹å¤§å°å’Œå¯¹åº”çš„å‚æ•°
MODEL_SIZES = {
    "tiny": {"params": "39M", "vram": "~1GB", "speed": "~32x"},
    "base": {"params": "74M", "vram": "~1GB", "speed": "~16x"},
    "small": {"params": "244M", "vram": "~2GB", "speed": "~6x"},
    "medium": {"params": "769M", "vram": "~5GB", "speed": "~2x"},
    "large": {"params": "1550M", "vram": "~10GB", "speed": "~1x"},
}


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    try:
        import whisper
        return True
    except ImportError:
        return False


def install_whisper():
    """å®‰è£… whisper åº“"""
    print("ğŸ“¦ æ­£åœ¨å®‰è£… openai-whisper...")
    import subprocess
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "openai-whisper"],
        capture_output=True,
        text=True
    )
    if result.returncode != 0:
        print(f"âŒ å®‰è£…å¤±è´¥: {result.stderr}")
        return False
    print("âœ… openai-whisper å®‰è£…æˆåŠŸ")
    return True


def download_model(model_size: str, model_path: str):
    """ä¸‹è½½æŒ‡å®šå¤§å°çš„ Whisper æ¨¡å‹"""
    import whisper

    print(f"\nğŸ”½ æ­£åœ¨ä¸‹è½½ Whisper {model_size} æ¨¡å‹...")
    print(f"   å‚æ•°é‡: {MODEL_SIZES[model_size]['params']}")
    print(f"   æ˜¾å­˜éœ€æ±‚: {MODEL_SIZES[model_size]['vram']}")
    print(f"   ç›¸å¯¹é€Ÿåº¦: {MODEL_SIZES[model_size]['speed']}")
    print(f"   ä¿å­˜è·¯å¾„: {model_path}")
    print()

    # è®¾ç½®ä¸‹è½½ç›®å½•
    os.makedirs(model_path, exist_ok=True)

    # ä¸‹è½½æ¨¡å‹ï¼ˆwhisper ä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
    try:
        model = whisper.load_model(model_size, download_root=model_path)
        print(f"\nâœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"   æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        return True
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ Whisper ASR æ¨¡å‹ç”¨äºæœ¬åœ°è¯­éŸ³è¯†åˆ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python download_asr_model.py                    # ä¸‹è½½é»˜è®¤çš„ base æ¨¡å‹
  python download_asr_model.py --size small       # ä¸‹è½½ small æ¨¡å‹
  python download_asr_model.py --size tiny --path ./my_models  # æŒ‡å®šè·¯å¾„

æ¨¡å‹å¤§å°è¯´æ˜:
  tiny   - 39M å‚æ•°, ~1GBæ˜¾å­˜, æœ€å¿«ä½†å‡†ç¡®åº¦æœ€ä½
  base   - 74M å‚æ•°, ~1GBæ˜¾å­˜, é€Ÿåº¦å’Œå‡†ç¡®åº¦å¹³è¡¡ (æ¨è)
  small  - 244M å‚æ•°, ~2GBæ˜¾å­˜, å‡†ç¡®åº¦è¾ƒå¥½
  medium - 769M å‚æ•°, ~5GBæ˜¾å­˜, å‡†ç¡®åº¦é«˜
  large  - 1550M å‚æ•°, ~10GBæ˜¾å­˜, å‡†ç¡®åº¦æœ€é«˜ä½†æœ€æ…¢
        """
    )

    parser.add_argument(
        "--size", "-s",
        choices=list(MODEL_SIZES.keys()),
        default="base",
        help="æ¨¡å‹å¤§å° (é»˜è®¤: base)"
    )

    parser.add_argument(
        "--path", "-p",
        default="./models/whisper",
        help="æ¨¡å‹ä¿å­˜è·¯å¾„ (é»˜è®¤: ./models/whisper)"
    )

    parser.add_argument(
        "--list", "-l",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹å¤§å°"
    )

    args = parser.parse_args()

    if args.list:
        print("\nå¯ç”¨çš„ Whisper æ¨¡å‹:\n")
        print(f"{'å¤§å°':<8} {'å‚æ•°é‡':<10} {'æ˜¾å­˜éœ€æ±‚':<12} {'ç›¸å¯¹é€Ÿåº¦':<10}")
        print("-" * 45)
        for size, info in MODEL_SIZES.items():
            print(f"{size:<8} {info['params']:<10} {info['vram']:<12} {info['speed']:<10}")
        print()
        return

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Whisper ASR æ¨¡å‹ä¸‹è½½å·¥å…·                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("âš ï¸ æœªå®‰è£… openai-whisper åº“")
        response = input("æ˜¯å¦ç°åœ¨å®‰è£…ï¼Ÿ(y/n): ").strip().lower()
        if response == 'y':
            if not install_whisper():
                sys.exit(1)
        else:
            print("è¯·å…ˆå®‰è£…: pip install openai-whisper")
            sys.exit(1)

    # ä¸‹è½½æ¨¡å‹
    model_path = Path(args.path).resolve()
    success = download_model(args.size, str(model_path))

    if success:
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… ä¸‹è½½å®Œæˆï¼                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  åœ¨ config.yaml ä¸­é…ç½®:                                   â•‘
â•‘                                                           â•‘
â•‘  voice:                                                   â•‘
â•‘    asr:                                                   â•‘
â•‘      mode: "local"                                        â•‘
â•‘      local:                                               â•‘
â•‘        modelPath: "{model_path}"
â•‘        modelSize: "{args.size}"
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
    else:
        sys.exit(1)


if __name__ == "__main__":
    main()
