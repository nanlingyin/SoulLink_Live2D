"""
ç»Ÿä¸€é…ç½®ç®¡ç†å™¨
æ‰€æœ‰é…ç½®ä» config.yaml è¯»å–ï¼Œç”¨æˆ·æ— éœ€ä¿®æ”¹ä»£ç 
"""

import os
import yaml
from typing import Dict, Any

from .models import LLMConfig, ServerConfig, AnimationConfig, ModelConfig, UIConfig


class ConfigManager:
    """
    ç»Ÿä¸€é…ç½®ç®¡ç†å™¨
    æ‰€æœ‰é…ç½®ä» config.yaml è¯»å–ï¼Œç”¨æˆ·æ— éœ€ä¿®æ”¹ä»£ç 
    """

    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = config_path
        self.llm = LLMConfig()
        self.server = ServerConfig()
        self.animation = AnimationConfig()
        self.model = ModelConfig()
        self.ui = UIConfig()
        self._raw_config: Dict[str, Any] = {}  # ä¿å­˜åŸå§‹é…ç½®ç”¨äºå‰ç«¯
        self.load()

    def load(self) -> None:
        """ä» config.yaml åŠ è½½æ‰€æœ‰é…ç½®"""
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self._raw_config = yaml.safe_load(f) or {}

                # åŠ è½½ LLM é…ç½®
                llm_data = self._raw_config.get('llm', {})
                api_data = llm_data.get('api', {})
                local_data = llm_data.get('local', {})

                self.llm = LLMConfig(
                    mode=llm_data.get('mode', 'api'),
                    provider=api_data.get('provider', 'openai'),
                    api_key=api_data.get('apiKey', ''),
                    base_url=api_data.get('baseUrl', 'https://api.openai.com/v1'),
                    model=api_data.get('model', 'gpt-4o-mini'),
                    temperature=api_data.get('temperature', 0.7),
                    max_tokens=api_data.get('maxTokens', 500),
                    # æœ¬åœ°æ¨¡å‹é…ç½®
                    local_base_model_path=local_data.get('baseModelPath', './ct2model/models/qwen2.5-1.5b-instruct'),
                    local_lora_model_path=local_data.get('loraModelPath', './ct2model/output/l2d-motion-lora/final'),
                    local_device=local_data.get('device', 'auto'),
                    local_temperature=local_data.get('temperature', 0.1),
                    local_max_new_tokens=local_data.get('maxNewTokens', 512)
                )

                # åŠ è½½æœåŠ¡å™¨é…ç½®
                server_data = self._raw_config.get('server', {})
                model_dir = self._raw_config.get('model', {}).get('directory', './l2d')
                self.server = ServerConfig(
                    host=server_data.get('host', '0.0.0.0'),
                    port=server_data.get('port', 3000),
                    model_dirs=server_data.get('modelDirs', [model_dir])
                )

                # åŠ è½½åŠ¨ç”»é…ç½®
                anim_data = self._raw_config.get('animation', {})
                self.animation = AnimationConfig(
                    default_duration=anim_data.get('defaultDuration', 1000),
                    easing=anim_data.get('easing', 'easeInOutCubic'),
                    auto_reset_delay=anim_data.get('autoResetDelay', 1500)
                )

                # åŠ è½½æ¨¡å‹é…ç½®
                model_data = self._raw_config.get('model', {})
                self.model = ModelConfig(
                    directory=model_data.get('directory', './l2d'),
                    default_scale=model_data.get('defaultScale', 0.8)
                )

                # åŠ è½½ UI é…ç½®
                ui_data = self._raw_config.get('ui', {})
                self.ui = UIConfig(
                    show_control_panel=ui_data.get('showControlPanel', True),
                    show_physics_params=ui_data.get('showPhysicsParams', False),
                    default_background=ui_data.get('defaultBackground', 0)
                )

                print(f"âœ… é…ç½®å·²åŠ è½½: {self.config_path}")
                print(f"   ğŸ¤– LLM æ¨¡å¼: {self.llm.mode}")
                if self.llm.mode == "local":
                    print(f"   ğŸ“¦ æœ¬åœ°æ¨¡å‹: {self.llm.local_base_model_path}")
                    print(f"   ğŸ”§ LoRA: {self.llm.local_lora_model_path}")
                else:
                    print(f"   ğŸŒ API: {self.llm.model} @ {self.llm.base_url}")
                print(f"   ğŸ¬ åŠ¨ç”»: duration={self.animation.default_duration}ms, easing={self.animation.easing}")

            except Exception as e:
                print(f"âš ï¸ åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

    def get_frontend_config(self) -> dict:
        """
        è·å–å‰ç«¯éœ€è¦çš„é…ç½®ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯å¦‚ API Keyï¼‰
        å‰ç«¯é€šè¿‡ /api/config è·å–è¿™äº›é…ç½®
        """
        return {
            "server": {
                "host": self.server.host,
                "port": self.server.port,
                "modelDirs": self.server.model_dirs
            },
            "llm": {
                "mode": self.llm.mode,
                "provider": self.llm.provider if self.llm.mode == "api" else "local",
                "model": self.llm.model if self.llm.mode == "api" else "qwen2.5-1.5b-lora",
                # ä¸æš´éœ² api_key å’Œ base_url
            },
            "animation": {
                "defaultDuration": self.animation.default_duration,
                "easing": self.animation.easing,
                "autoResetDelay": self.animation.auto_reset_delay
            },
            "model": {
                "directory": self.model.directory,
                "defaultScale": self.model.default_scale
            },
            "ui": {
                "showControlPanel": self.ui.show_control_panel,
                "showPhysicsParams": self.ui.show_physics_params,
                "defaultBackground": self.ui.default_background
            }
        }
